{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9167690d",
   "metadata": {},
   "source": [
    "## Github URL https://github.com/jun13245/DL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218bfdd3",
   "metadata": {},
   "source": [
    "## Settings\n",
    "  important required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fae45b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e409fc",
   "metadata": {},
   "source": [
    "## hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9da7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 16\n",
    "learning_rate = 0.0001\n",
    "epoch = 10\n",
    "\n",
    "n_node =1024\n",
    "dropratio = 0.5\n",
    "\n",
    "imgsize = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2adb0a",
   "metadata": {},
   "source": [
    "## Data Loader\n",
    " 트레이닝 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20d7185d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torchvision/transforms/transforms.py:220: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    }
   ],
   "source": [
    "img_dir = \"animal/train\"\n",
    "train_data = dset.ImageFolder(img_dir, transforms.Compose([\n",
    "            transforms.CenterCrop(imgsize*2),   \n",
    "            transforms.RandomCrop(imgsize),     \n",
    "            transforms.RandomHorizontalFlip(),      \n",
    "    \n",
    "            transforms.Scale(imgsize),\n",
    "            transforms.ToTensor()\n",
    "            ]))\n",
    "print(train_data.__len__())\n",
    "\n",
    "train_batch = data.DataLoader(train_data, batch_size=batch_size,\n",
    "                            shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf529c4b",
   "metadata": {},
   "source": [
    "## 고정된 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f7386f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of classes: 2\n",
      "['cow', 'panda']\n",
      "{'panda': 1, 'cow': 0}\n",
      "32\n",
      "Training: 32, Dev: 12, Test: 12,\n"
     ]
    }
   ],
   "source": [
    "#dev data\n",
    "img_dir = \"animal/val\"\n",
    "dev_data = dset.ImageFolder(img_dir, transforms.Compose([\n",
    "            transforms.CenterCrop(size=imgsize),\n",
    "            transforms.Scale(imgsize),\n",
    "            transforms.ToTensor()\n",
    "            ]))\n",
    "dev_batch = data.DataLoader(dev_data, batch_size=batch_size,\n",
    "                            shuffle=True, num_workers=2)\n",
    "\n",
    "#test data\n",
    "img_dir = \"animal/test\"\n",
    "test_data = dset.ImageFolder(img_dir, transforms.Compose([\n",
    "            transforms.CenterCrop(size=imgsize),\n",
    "            transforms.Scale(imgsize),\n",
    "            transforms.ToTensor()\n",
    "            ]))\n",
    "test_batch = data.DataLoader(test_data, batch_size=batch_size,\n",
    "                            shuffle=True, num_workers=2)\n",
    "\n",
    "nclass = len(train_data.classes)\n",
    "print(\"# of classes: %d\" %nclass)\n",
    "print(train_data.classes)\n",
    "print(train_data.class_to_idx)\n",
    "print(train_data.__len__())\n",
    "\n",
    "print(\"Training: %d, Dev: %d, Test: %d,\" \n",
    "      %(train_data.__len__(), dev_data.__len__(), test_data.__len__())),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "720e5bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cow', 'panda']\n",
      "['cow', 'panda']\n",
      "['cow', 'panda']\n"
     ]
    }
   ],
   "source": [
    "print(train_data.classes)\n",
    "print(dev_data.classes)\n",
    "print(test_data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb087ef",
   "metadata": {},
   "source": [
    "## Model\n",
    "pretrained VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e44de21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features\n",
      "avgpool\n",
      "classifier\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (17): ReLU(inplace=True)\n",
      "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (24): ReLU(inplace=True)\n",
      "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (26): ReLU(inplace=True)\n",
      "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (31): ReLU(inplace=True)\n",
      "  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (33): ReLU(inplace=True)\n",
      "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (35): ReLU(inplace=True)\n",
      "  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg = models.vgg19(pretrained=True)\n",
    "\n",
    "for name,module in vgg.named_children():\n",
    "    print(name)\n",
    "\n",
    "print(list(vgg.children())[0])\n",
    "print(list(vgg.children())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2fa71e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "print(list(vgg.children())[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f982fa",
   "metadata": {},
   "source": [
    "## customized fully model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01f51120",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dim = 64\n",
    "fsize = imgsize / 32\n",
    "\n",
    "class MyVGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyVGG, self).__init__()\n",
    "        # [0] : features(conv), [1]: classifier(fc)\n",
    "        self.layer0 = nn.Sequential(*list(vgg.children())[0])\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(8*base_dim * fsize * fsize, n_node),\n",
    "            nn.BatchNorm1d(n_node),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(dropratio), # 0.3만큼 drop\n",
    "            \n",
    "            nn.Linear(n_node, n_node),\n",
    "            nn.BatchNorm1d(n_node),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(dropratio),\n",
    "            \n",
    "            nn.Linear(n_node, n_node),\n",
    "            nn.BatchNorm1d(n_node),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(dropratio),\n",
    "            \n",
    "            nn.Linear(n_node, nclass),\n",
    "        )\n",
    "        #weight initialization\n",
    "        for m in self.layer1.modules():\n",
    "            #print(m)\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal(m.weight.data)   #REUL\n",
    "                m.bias.data.fill_(0)\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal(m.weight.data)\n",
    "                m.bias.data.fill_(0)\n",
    "    def forward(self, x):\n",
    "        #layer0의 사이즈를 무식하게 프린트하여 알아낼 수 있음 (batch_size, x,x,x)\n",
    "        #print(x, size())\n",
    "        out = self.layer0(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.layer1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27edbb7",
   "metadata": {},
   "source": [
    "Model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e4692ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/ipykernel/__main__.py:35: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    }
   ],
   "source": [
    "model = MyVGG() #.cuda()\n",
    "\n",
    "for params in model.layer0.parameters():\n",
    "    params.required_grad = False\n",
    "    \n",
    "for params in model.layer1.parameters():\n",
    "    params.required_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31e048d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (17): ReLU(inplace=True)\n",
      "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (24): ReLU(inplace=True)\n",
      "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (26): ReLU(inplace=True)\n",
      "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (31): ReLU(inplace=True)\n",
      "  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (33): ReLU(inplace=True)\n",
      "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (35): ReLU(inplace=True)\n",
      "  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=32768, out_features=1024, bias=True)\n",
      "  (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout2d(p=0.5, inplace=False)\n",
      "  (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): ReLU()\n",
      "  (7): Dropout2d(p=0.5, inplace=False)\n",
      "  (8): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (9): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (10): ReLU()\n",
      "  (11): Dropout2d(p=0.5, inplace=False)\n",
      "  (12): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for name in model.children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40a80b6",
   "metadata": {},
   "source": [
    "Optimizer & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cb204dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.layer1.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a44be",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4501e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 layer, n_node: 1024, dropratio: 0.50\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "total_time = 0\n",
    "disp_step = 10\n",
    "\n",
    "to_train = True\n",
    "if (to_train == False):\n",
    "    netname = './nets/cowpanda_vgg19_10.pkl'\n",
    "    model = torch.load(netname)\n",
    "else:   \n",
    "    print(\"3 layer, n_node: %d, dropratio: %.2f\" %(n_node, dropratio))\n",
    "    model.eval()#evaluation(test)mode로 바꾸기->dropout, batch normalization에 영향\n",
    "    train_corr = utils.ComputeCorr(train_batch, model)\n",
    "    dev_corr = utils.ComputeCorr(dev_batch, model)\n",
    "    test_corr = utils.ComputeCorr(test_batch, model)\n",
    "    print(\"Correct of train: %.2f, dev: %.2f, test: %.2f\" \n",
    "          %(train_corr, dev_corr, test_corr))\n",
    "    model.train()\n",
    "    \n",
    "    netname = './nets/cowpanda_vgg19'\n",
    "\n",
    "    #graph 그리기\n",
    "    x_epoch = []\n",
    "    y_train_err = []\n",
    "    y_dev_err = []\n",
    "    y_test_err = []\n",
    "    \n",
    "    x_epoch.append(0)\n",
    "    y_train_err.append(100.0 - train_corr)\n",
    "    y_dev_err.append(100.0 - dev_corr)\n",
    "    y_test_err.append(100.0 - test_corr)\n",
    "    \n",
    "    #학습을 재시작한다면\n",
    "    #netname = '../nets/media_pre_vgg19.pkl'\n",
    "    #model = torch.load(netname)\n",
    "    #파라미터 학습 여부 결정\n",
    "    #for params in model.layer0.parameters():\n",
    "    #    params.required_grad = False    \n",
    "    #for params in model.layer1.parameters():\n",
    "    #    params.required_grad = True\n",
    "    #for i in range(34, epoch):\n",
    "    \n",
    "    #재시작하지 않는다면\n",
    "    for i in range(epoch):\n",
    "        start_time = time.time()\n",
    "        print(\"%d..\" %i),\n",
    "        for img,label in train_batch:\n",
    "            img = Variable(img) \n",
    "            label = Variable(label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(img)\n",
    "            loss = loss_func(output,label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        total_time += duration\n",
    "        if (i % disp_step == 0) or (i == epoch-1):\n",
    "            torch.save(model, netname+'_%d.pkl'%i, )\n",
    "            print(\"\\n[%d/%d] loss: %.3f, \" %(i, epoch, (loss.cpu()).data.numpy())),\n",
    "            \n",
    "            # evaluation(test) mode로 바꾸기 -> dropout, batch normalization에 영향\n",
    "            model.eval()\n",
    "            \n",
    "            #train, dev, train accr\n",
    "            train_corr = utils.ComputeCorr(train_batch, model)\n",
    "            dev_corr = utils.ComputeCorr(dev_batch, model)\n",
    "            test_corr = utils.ComputeCorr(test_batch, model)\n",
    "            print(\"Correct of train: %.2f, dev: %.2f, test: %.2f, \" \n",
    "                  %(train_corr, dev_corr, test_corr)),\n",
    "            \n",
    "            model.train()            \n",
    "            print(\"time: %.2f sec..\" %(total_time))\n",
    "            \n",
    "            #graph 그리기\n",
    "            x_epoch.append(i + 1)\n",
    "            y_train_err.append(100.0 - train_corr)\n",
    "            y_dev_err.append(100.0 - dev_corr)\n",
    "            y_test_err.append(100.0 - test_corr)\n",
    "    print(\"Total time: %.2f sec\" %total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dcf9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (to_train):\n",
    "    plt.plot(x_epoch, y_train_err, color='black', label='train err', linestyle='--')\n",
    "    plt.plot(x_epoch, y_dev_err, color='red', label='dev err')\n",
    "    plt.plot(x_epoch, y_test_err, color='blue', label='test err')\n",
    "    \n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('err')\n",
    "    plt.title('epoch & err graph')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee4bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()#evaluation(test) mode로 바꾸기 -> dropout, batch normalization 에 영향\n",
    "utils.EvaluateClassifier(dev_batch, model, dev_data.classes, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e270cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_, _,_ = utils.EvaluateClassifier(test_batch, model, test_data.classes, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e83591",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.VisTFPred(test_batch, model, test_data.classes, batch_size, i_n=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p27",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
